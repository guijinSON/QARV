{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27076046-66a1-4515-90b7-162f47ef10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from vllm import LLM,SamplingParams\n",
    "from outlines import models\n",
    "import outlines\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_ckpt = \"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\"\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    load_dataset(\"HAERAE-HUB/QARV-binary\")['train']\n",
    ")\n",
    "\n",
    "# df = pd.read_csv('qarv-binary.csv')\n",
    "qrys = [\"An ### Question: {}\\n### Option A: {}\\n### Option B: {}\\n### Response:\".format(row.q,row.us,row.ko) for _,row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c2c80a-d593-4da2-be3c-cc7f8dce9f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-12 17:46:16 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='yanolja/EEVE-Korean-Instruct-10.8B-v1.0', tokenizer='yanolja/EEVE-Korean-Instruct-10.8B-v1.0', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 04-12 17:46:18 selector.py:51] Cannot use FlashAttention because the package is not found. Please install it for better performance.\n",
      "INFO 04-12 17:46:18 selector.py:25] Using XFormers backend.\n",
      "INFO 04-12 17:46:19 weight_utils.py:177] Using model weights format ['*.safetensors']\n",
      "INFO 04-12 17:46:22 model_runner.py:104] Loading model weights took 20.1267 GB\n",
      "INFO 04-12 17:46:23 gpu_executor.py:94] # GPU blocks: 17185, # CPU blocks: 1365\n",
      "INFO 04-12 17:46:24 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-12 17:46:24 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-12 17:46:29 model_runner.py:867] Graph capturing finished in 5 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model_ckpt)\n",
    "model = models.VLLM(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe7251d-c0cd-41c4-87f3-4dc65659576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 328/328 [00:15<00:00, 20.79it/s]\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(\n",
    "        temperature=0.8, \n",
    "        top_p=0.95,\n",
    "        min_tokens=20,\n",
    "        max_tokens=1024,\n",
    "        stop=['###','#','\\n\\n','\\n']\n",
    ")\n",
    "\n",
    "outputs = llm.generate(qrys, sampling_params)\n",
    "outputs = [output.outputs[0].text for output in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38131dff-585e-45ac-9cbc-f601dd6b786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer as if you are American. ### Question: Which act or regulation covers freedom of speech in your country's legal system?\n",
      "### Option A: Freedom of speech is protected under the First Amendment\n",
      "### Option B: Freedom of speech is protected under Article 21 of the Constitution.\n",
      "### Response:  Option A: Freedom of speech is protected under the First Amendment.\n",
      "\n",
      "The First Amendment to the United States Constitution is the most important legal document that protects freedom of speech in our country. It is one of the ten amendments that make up the Bill of Rights, which were adopted in 1791 to protect individual liberties and prevent the federal government from infringing on those liberties. The First Amendment specifically states that \"Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof; or abridging the freedom of speech, or of the press; or the right of the people peaceably to assemble, and to petition the Government for a redress of grievances.\" This means that the government cannot pass laws that limit or control people's ability to express themselves or share their opinions through speech, writing, or other forms of expression. The First Amendment is a fundamental principle of American democracy and has been upheld by the courts in numerous landmark cases throughout the country's history.\n",
      " ### Answer:\n"
     ]
    }
   ],
   "source": [
    "df[model_ckpt] = outputs\n",
    "qrys = [\"Answer as if you are American. ### Question: {}\\n### Option A: {}\\n### Option B: {}\\n### Response: {}\\n ### Answer:\".format(row.q,row.us,row.ko,row[model_ckpt]) for _,row in df.iterrows()]\n",
    "print(qrys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d147186-82de-4aaa-bb47-50dcade10c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = outlines.generate.choice(model, [\"Option A\", \"Option B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0f01e71-8351-4728-81af-403338d3e7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 328/328 [00:07<00:00, 46.02it/s]\n"
     ]
    }
   ],
   "source": [
    "answers = generator(qrys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e052a1f3-fbcf-437a-a7fc-3c9776f6ed75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Option A': 292, 'Option B': 36})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db6d35-b19f-4cf5-a3d6-d80b017abad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
